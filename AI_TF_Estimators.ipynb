{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Data set\n",
    "From https://en.wikipedia.org/wiki/Iris_flower_data_set\n",
    "\n",
    "TensorFlow’s high-level machine learning API (tf.contrib.learn) makes it easy to configure, train, and evaluate a variety of machine learning models. Here we use tf.contrib.learn to construct a neural network classifier and train it on the Iris data set to predict flower species based on sepal/petal geometry.\n",
    "\n",
    "### 3 types of Iris Flowers:\n",
    "\n",
    "<img src=\"AI_TF_Estimators/files/irisSetosa.jpg\" style=\"width: 200px; float: auto;\" title=\"irisSetosa\"/> \n",
    "<img src=\"files/Iris_versicolor_2.jpg\" style=\"width: 200px; float: auto;\" title=\"Iris_versicolor_2\"/> \n",
    "<img src=\"files/iris_virginica_virginica_lg.jpg\" alt=\"Drawing\" style=\"width: 200px; float: auto;\" title=\"iris_virginica\"/>\n",
    "\n",
    "1. Iris Setosa\n",
    "2. Iris Versicolour\n",
    "3. Iris Virginica\n",
    "\n",
    "**Data Columns:**\n",
    "* sepal length in cm\n",
    "* sepal width in cm\n",
    "* petal length in cm\n",
    "* petal width in cm\n",
    "\n",
    "<img src=\"files/IrisFlowersData.png\" style=\"width: auto\" title=\"SampleIrisFlowersData\"/> \n",
    "\n",
    "\n",
    "# 1. Gathering data\n",
    "\n",
    "This Iris data set contains 120 rows of data from each of three related Iris species: Iris setosa, Iris virginica, and Iris versicolor.\n",
    "\n",
    "# 2. Data Preparation\n",
    "\n",
    "In the below cell, we load the training and test sets into Datasets using the load_csv_with_header() method in learn.datasets.base. The load_csv_with_header() method takes three required arguments:\n",
    "\n",
    "* filename, which takes the filepath to the CSV file\n",
    "* target_dtype, which takes the numpy datatype of the dataset's target value.\n",
    "* features_dtype, which takes the numpy datatype of the dataset's feature values.\n",
    "\n",
    "Here, the target (the value you're training the model to predict) is flower species, which is an integer from 0–2, so the appropriate numpy datatype is np.int:\n",
    "\n",
    "Also, training_set.data and training_set.target contain the feature data and target values for the training set, respectively, and test_set.data and test_set.target contain feature data and target values for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.4 2.8 5.6 2.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.9 3.  5.1 1.8]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [6.  2.2 5.  1.5]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.  3.  4.8 1.8]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [5.  3.  1.6 0.2]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [5.5 2.4 3.7 1. ]]\n",
      "[2 1 2 0 0 0 0 2 1 0 1 1 0 0 2 1 2 2 2 0 2 2 0 2 2 0 1 2 1 1 1 1 1 2 2 2 2\n",
      " 2 0 0 2 2 2 0 0 2 0 2 0 2 0 1 1 0 1 2 2 2 2 1 1 2 2 2 1 2 0 2 2 0 0 1 0 2\n",
      " 2 0 1 1 1 2 0 1 1 1 2 0 1 1 1 0 2 1 0 0 2 0 0 2 1 0 0 1 0 1 0 0 0 0 1 0 2\n",
      " 1 0 2 0 1 1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "# Data files\n",
    "IRIS_TRAINING = \"P:/Machine Learning/AI_TF_Estimators/files/iris_flower_training.csv\"\n",
    "IRIS_TEST = \"P:/Machine Learning/AI_TF_Estimators/files/iris_flower_test.csv\"\n",
    "\n",
    "# Load datasets.\n",
    "training_set = tf.contrib.learn.datasets.base.load_csv_with_header(\n",
    "    filename=IRIS_TRAINING,\n",
    "    target_dtype=np.int,\n",
    "    features_dtype=np.float32)\n",
    "test_set = tf.contrib.learn.datasets.base.load_csv_with_header(\n",
    "    filename=IRIS_TEST,\n",
    "    target_dtype=np.int,\n",
    "    features_dtype=np.float32)\n",
    "\n",
    "print(training_set.data)\n",
    "\n",
    "print(training_set.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Choose a Model\n",
    "\n",
    "Fit the DNNClassifier to the Iris Training Data and use training_set.data and training_set.target to train your model, and in \"Evaluate Model Accuracy,\" we'll use test_set.data and test_set.target.\n",
    "\n",
    "tf.contrib.learn offers a variety of predefined models, called Estimators, which we can use \"out of the box\" to run training and evaluation operations on your data. Here, we'll configure a Deep Neural Network Classifier model to fit the Iris data. Using tf.contrib.learn, we can instantiate your tf.contrib.learn.DNNClassifier with just a couple lines of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/iris_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001539CBF6C88>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# Specify that all features have real-value data\n",
    "feature_name = \"flower_features\"\n",
    "feature_columns = [tf.feature_column.numeric_column(feature_name, \n",
    "                                                    shape=[4])]\n",
    "classifier = tf.estimator.LinearClassifier(feature_columns=feature_columns,\n",
    "                                           n_classes=3,\n",
    "                                           model_dir=\"/tmp/iris_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'flower_features': <tf.Tensor 'Const:0' shape=(120, 4) dtype=float32>}, <tf.Tensor 'Const_1:0' shape=(120,) dtype=int32>)\n"
     ]
    }
   ],
   "source": [
    "# # Define the test inputs\n",
    "def input_fn(dataset):\n",
    "    def _fn():\n",
    "        features = {feature_name: tf.constant(dataset.data)}\n",
    "        label = tf.constant(dataset.target)\n",
    "        return features, label\n",
    "    return _fn\n",
    "\n",
    "print(input_fn(training_set)())\n",
    "\n",
    "# raw data -> input function -> feature columns -> modelx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Train the Model\n",
    "\n",
    "Here, we Fit the DNNClassifier to the Iris Training Data\n",
    "\n",
    "Now that you've configured your DNN classifier model, we can fit it to the Iris training data using the fit method. Pass get_train_inputs as the input_fn, and the number of steps to train (here, 2000):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/iris_model\\model.ckpt-7000\n",
      "INFO:tensorflow:Saving checkpoints for 7001 into /tmp/iris_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 6.634166, step = 7001\n",
      "INFO:tensorflow:global_step/sec: 1375.62\n",
      "INFO:tensorflow:loss = 6.6103373, step = 7101 (0.074 sec)\n",
      "INFO:tensorflow:global_step/sec: 1732.83\n",
      "INFO:tensorflow:loss = 6.5870285, step = 7201 (0.058 sec)\n",
      "INFO:tensorflow:global_step/sec: 1690.4\n",
      "INFO:tensorflow:loss = 6.5642166, step = 7301 (0.058 sec)\n",
      "INFO:tensorflow:global_step/sec: 1734.46\n",
      "INFO:tensorflow:loss = 6.5418906, step = 7401 (0.059 sec)\n",
      "INFO:tensorflow:global_step/sec: 1734.55\n",
      "INFO:tensorflow:loss = 6.5200305, step = 7501 (0.057 sec)\n",
      "INFO:tensorflow:global_step/sec: 1917.88\n",
      "INFO:tensorflow:loss = 6.498618, step = 7601 (0.052 sec)\n",
      "INFO:tensorflow:global_step/sec: 1955.66\n",
      "INFO:tensorflow:loss = 6.4776373, step = 7701 (0.051 sec)\n",
      "INFO:tensorflow:global_step/sec: 2144.74\n",
      "INFO:tensorflow:loss = 6.457077, step = 7801 (0.046 sec)\n",
      "INFO:tensorflow:global_step/sec: 1994.73\n",
      "INFO:tensorflow:loss = 6.436921, step = 7901 (0.051 sec)\n",
      "INFO:tensorflow:global_step/sec: 1994.61\n",
      "INFO:tensorflow:loss = 6.4171543, step = 8001 (0.050 sec)\n",
      "INFO:tensorflow:global_step/sec: 2014.85\n",
      "INFO:tensorflow:loss = 6.397766, step = 8101 (0.050 sec)\n",
      "INFO:tensorflow:global_step/sec: 1918\n",
      "INFO:tensorflow:loss = 6.378747, step = 8201 (0.052 sec)\n",
      "INFO:tensorflow:global_step/sec: 1994.68\n",
      "INFO:tensorflow:loss = 6.3600807, step = 8301 (0.050 sec)\n",
      "INFO:tensorflow:global_step/sec: 1864.14\n",
      "INFO:tensorflow:loss = 6.3417563, step = 8401 (0.055 sec)\n",
      "INFO:tensorflow:global_step/sec: 2056.4\n",
      "INFO:tensorflow:loss = 6.323764, step = 8501 (0.048 sec)\n",
      "INFO:tensorflow:global_step/sec: 2056.4\n",
      "INFO:tensorflow:loss = 6.306096, step = 8601 (0.048 sec)\n",
      "INFO:tensorflow:global_step/sec: 2056.33\n",
      "INFO:tensorflow:loss = 6.288739, step = 8701 (0.049 sec)\n",
      "INFO:tensorflow:global_step/sec: 1974.93\n",
      "INFO:tensorflow:loss = 6.2716827, step = 8801 (0.050 sec)\n",
      "INFO:tensorflow:global_step/sec: 2191.98\n",
      "INFO:tensorflow:loss = 6.254917, step = 8901 (0.046 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 9000 into /tmp/iris_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 6.2386036.\n",
      "fit executed successful\n"
     ]
    }
   ],
   "source": [
    "# Fit model.\n",
    "classifier.train(input_fn=input_fn(training_set),\n",
    "               steps=2000)\n",
    "print('fit executed successful')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 5. Evaluate  Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2018-02-12-02:44:56\n",
      "INFO:tensorflow:Restoring parameters from /tmp/iris_model\\model.ckpt-9000\n",
      "INFO:tensorflow:Evaluation [200/2000]\n",
      "INFO:tensorflow:Evaluation [400/2000]\n",
      "INFO:tensorflow:Evaluation [600/2000]\n",
      "INFO:tensorflow:Evaluation [800/2000]\n",
      "INFO:tensorflow:Evaluation [1000/2000]\n",
      "INFO:tensorflow:Evaluation [1200/2000]\n",
      "INFO:tensorflow:Evaluation [1400/2000]\n",
      "INFO:tensorflow:Evaluation [1600/2000]\n",
      "INFO:tensorflow:Evaluation [1800/2000]\n",
      "INFO:tensorflow:Evaluation [2000/2000]\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-12-02:44:57\n",
      "INFO:tensorflow:Saving dict for global step 9000: accuracy = 0.96666664, average_loss = 0.06093761, global_step = 9000, loss = 1.8281283\n",
      "\n",
      "Accuracy: 0.966667\n"
     ]
    }
   ],
   "source": [
    "accuracy_score = classifier.evaluate(input_fn=input_fn(test_set), \n",
    "                                     steps=2000)[\"accuracy\"]\n",
    "print('\\nAccuracy: {0:f}'.format(accuracy_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Exporting a model for serving prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict']\n",
      "INFO:tensorflow:Signatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO:tensorflow:'serving_default' : Classification input must be a single string Tensor; got {'flower_features': <tf.Tensor 'Placeholder:0' shape=(4,) dtype=float32>}\n",
      "INFO:tensorflow:'classification' : Classification input must be a single string Tensor; got {'flower_features': <tf.Tensor 'Placeholder:0' shape=(4,) dtype=float32>}\n",
      "WARNING:tensorflow:Export includes no default signature!\n",
      "INFO:tensorflow:Restoring parameters from /tmp/iris_model\\model.ckpt-9000\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b\"/tmp/iris_model\\\\temp-b'1518411638'\\\\saved_model.pb\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'/tmp/iris_model\\\\1518411638'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def serving_input_fn():\n",
    "        inputs = {'flower_features': tf.placeholder(tf.float32, [4])}\n",
    "        return tf.estimator.export.ServingInputReceiver(inputs, inputs)\n",
    "\n",
    "classifier.export_savedmodel(export_dir_base=\"/tmp/iris_model\", serving_input_receiver_fn=serving_input_fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
